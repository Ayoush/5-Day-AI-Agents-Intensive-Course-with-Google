{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gemini API key loaded from .env file (first 10 chars: AIzaSyCxBj...)\n",
            "Verified: GOOGLE_API_KEY is set in environment (length: 39 chars)\n",
            "ADK will use GOOGLE_API_KEY\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "try:\n",
        "    env_file = Path('.env')\n",
        "    if env_file.exists():\n",
        "        load_dotenv(dotenv_path=env_file, override=True)\n",
        "        google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "        if not google_api_key:\n",
        "            raise ValueError(\"GOOGLE_API_KEY not found in .env file\")\n",
        "        print(f\"Gemini API key loaded from .env file (first 10 chars: {google_api_key[:10]}...)\")\n",
        "        print(f\"Verified: GOOGLE_API_KEY is set in environment (length: {len(google_api_key)} chars)\")\n",
        "        print(\"ADK will use GOOGLE_API_KEY\")\n",
        "except Exception as e:\n",
        "    print(f\"Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your .env file. Details: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADK components imported successfully.\n"
          ]
        }
      ],
      "source": [
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.models.google_llm import Gemini\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.tools import load_memory, preload_memory\n",
        "from google.genai import types\n",
        "\n",
        "print(\"ADK components imported successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined.\n"
          ]
        }
      ],
      "source": [
        "async def run_session(\n",
        "    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n",
        "):\n",
        "    print(f\"\\n### Session: {session_id}\")\n",
        "\n",
        "    try:\n",
        "        session = await session_service.create_session(\n",
        "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
        "        )\n",
        "    except:\n",
        "        session = await session_service.get_session(\n",
        "            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
        "        )\n",
        "\n",
        "    if isinstance(user_queries, str):\n",
        "        user_queries = [user_queries]\n",
        "\n",
        "    for query in user_queries:\n",
        "        print(f\"\\nUser > {query}\")\n",
        "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
        "\n",
        "        async for event in runner_instance.run_async(\n",
        "            user_id=USER_ID, session_id=session.id, new_message=query_content\n",
        "        ):\n",
        "            if event.is_final_response() and event.content and event.content.parts:\n",
        "                text = event.content.parts[0].text\n",
        "                if text and text != \"None\":\n",
        "                    print(f\"Model: > {text}\")\n",
        "\n",
        "\n",
        "print(\"Helper functions defined.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "retry_config = types.HttpRetryOptions(\n",
        "    attempts=5,\n",
        "    exp_base=7,\n",
        "    initial_delay=1,\n",
        "    http_status_codes=[429, 500, 503, 504],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "memory_service = InMemoryMemoryService()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent created\n"
          ]
        }
      ],
      "source": [
        "APP_NAME = \"RecipeAssistantApp\"\n",
        "USER_ID = \"demo_user\"\n",
        "\n",
        "recipe_agent = LlmAgent(\n",
        "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
        "    name=\"RecipeAssistantAgent\",\n",
        "    instruction=\"Answer user questions about recipes and dietary preferences in simple words.\",\n",
        ")\n",
        "\n",
        "print(\"Agent created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent and Runner created with memory support.\n"
          ]
        }
      ],
      "source": [
        "session_service = InMemorySessionService()\n",
        "\n",
        "runner = Runner(\n",
        "    agent=recipe_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        "    memory_service=memory_service,\n",
        ")\n",
        "\n",
        "print(\"Agent and Runner created with memory support.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: conversation-01\n",
            "\n",
            "User > I am vegetarian and I love Italian cuisine. Can you suggest a pasta recipe?\n",
            "Model: > Sure! How about a delicious **Pasta Primavera**?\n",
            "\n",
            "It's a vegetarian Italian classic! It means \"spring pasta\" and is usually made with lots of fresh vegetables. You can use whatever veggies you have on hand, like:\n",
            "\n",
            "*   Broccoli\n",
            "*   Zucchini\n",
            "*   Bell peppers\n",
            "*   Asparagus\n",
            "*   Peas\n",
            "*   Carrots\n",
            "\n",
            "You'll typically cook pasta, then sauté the vegetables with garlic and olive oil. Everything is tossed together with some herbs and maybe a little bit of cream or a light sauce. It's super easy and healthy!\n",
            "\n",
            "Does that sound good?\n"
          ]
        }
      ],
      "source": [
        "await run_session(\n",
        "    runner,\n",
        "    \"I am vegetarian and I love Italian cuisine. Can you suggest a pasta recipe?\",\n",
        "    \"conversation-01\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session contains:\n",
            "  user: I am vegetarian and I love Italian cuisine. Can you suggest ...\n",
            "  model: Sure! How about a delicious **Pasta Primavera**?\n",
            "\n",
            "It's a veg...\n"
          ]
        }
      ],
      "source": [
        "session = await session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
        ")\n",
        "\n",
        "print(\"Session contains:\")\n",
        "for event in session.events:\n",
        "    text = (\n",
        "        event.content.parts[0].text[:60]\n",
        "        if event.content and event.content.parts\n",
        "        else \"(empty)\"\n",
        "    )\n",
        "    print(f\"  {event.content.role}: {text}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Session added to memory.\n"
          ]
        }
      ],
      "source": [
        "await memory_service.add_session_to_memory(session)\n",
        "\n",
        "print(\"Session added to memory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent with load_memory tool created.\n"
          ]
        }
      ],
      "source": [
        "recipe_agent = LlmAgent(\n",
        "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
        "    name=\"RecipeAssistantAgent\",\n",
        "    instruction=\"Answer user questions about recipes and dietary preferences. Use load_memory tool if you need to recall past conversations about dietary restrictions or cuisine preferences.\",\n",
        "    tools=[load_memory],\n",
        ")\n",
        "\n",
        "print(\"Agent with load_memory tool created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: preference-test\n",
            "\n",
            "User > What cuisine do I prefer?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        }
      ],
      "source": [
        "runner = Runner(\n",
        "    agent=recipe_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        "    memory_service=memory_service,\n",
        ")\n",
        "\n",
        "await run_session(runner, \"What cuisine do I prefer?\", \"preference-test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: dietary-session-01\n",
            "\n",
            "User > I am allergic to peanuts and tree nuts.\n",
            "Model: > Thanks for letting me know. I'll be sure to avoid recipes with peanuts and tree nuts.\n"
          ]
        }
      ],
      "source": [
        "await run_session(runner, \"I am allergic to peanuts and tree nuts.\", \"dietary-session-01\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dietary session saved to memory.\n"
          ]
        }
      ],
      "source": [
        "dietary_session = await session_service.get_session(\n",
        "    app_name=APP_NAME, user_id=USER_ID, session_id=\"dietary-session-01\"\n",
        ")\n",
        "\n",
        "await memory_service.add_session_to_memory(dietary_session)\n",
        "\n",
        "print(\"Dietary session saved to memory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: dietary-session-02\n",
            "\n",
            "User > What are my dietary restrictions?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
          ]
        }
      ],
      "source": [
        "await run_session(\n",
        "    runner, \"What are my dietary restrictions?\", \"dietary-session-02\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search Results:\n",
            "  Found 1 relevant memories\n",
            "\n",
            "  [RecipeAssistantAgent]: Sure! How about a delicious **Pasta Primavera**?\n",
            "\n",
            "It's a vegetarian Italian clas...\n"
          ]
        }
      ],
      "source": [
        "search_response = await memory_service.search_memory(\n",
        "    app_name=APP_NAME, user_id=USER_ID, query=\"What are the user's dietary restrictions?\"\n",
        ")\n",
        "\n",
        "print(\"Search Results:\")\n",
        "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
        "print()\n",
        "\n",
        "for memory in search_response.memories:\n",
        "    if memory.content and memory.content.parts:\n",
        "        text = memory.content.parts[0].text[:80]\n",
        "        print(f\"  [{memory.author}]: {text}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Callback created.\n"
          ]
        }
      ],
      "source": [
        "async def auto_save_to_memory(callback_context):\n",
        "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
        "        callback_context._invocation_context.session\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"Callback created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent created with automatic memory saving.\n"
          ]
        }
      ],
      "source": [
        "auto_memory_agent = LlmAgent(\n",
        "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
        "    name=\"AutoMemoryRecipeAgent\",\n",
        "    instruction=\"Answer user questions about recipes and dietary preferences.\",\n",
        "    tools=[preload_memory],\n",
        "    after_agent_callback=auto_save_to_memory,\n",
        ")\n",
        "\n",
        "print(\"Agent created with automatic memory saving.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Runner created.\n"
          ]
        }
      ],
      "source": [
        "auto_runner = Runner(\n",
        "    agent=auto_memory_agent,\n",
        "    app_name=APP_NAME,\n",
        "    session_service=session_service,\n",
        "    memory_service=memory_service,\n",
        ")\n",
        "\n",
        "print(\"Runner created.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: auto-save-test\n",
            "\n",
            "User > I prefer spicy food and I love Thai cuisine!\n",
            "Model: > Great! How about a spicy **Thai Green Curry**?\n",
            "\n",
            "It's a flavorful and aromatic dish that can easily be made vegetarian and nut-free. The key ingredients usually include:\n",
            "\n",
            "*   **Green curry paste:** This is where the spice comes from! You can adjust the amount to control the heat.\n",
            "*   **Coconut milk:** For a creamy base.\n",
            "*   **Vegetables:** Think bamboo shoots, bell peppers, zucchini, eggplant, and green beans.\n",
            "*   **Protein:** Tofu is a fantastic vegetarian option.\n",
            "*   **Thai basil and cilantro:** For fresh, vibrant flavor.\n",
            "\n",
            "It's typically served with jasmine rice.\n",
            "\n",
            "Does a spicy Thai Green Curry sound appealing to you?\n",
            "\n",
            "### Session: auto-save-test-2\n",
            "\n",
            "User > What type of cuisine do I like?\n",
            "Model: > You like Italian and Thai cuisine. You also mentioned that you prefer spicy food.\n"
          ]
        }
      ],
      "source": [
        "await run_session(\n",
        "    auto_runner,\n",
        "    \"I prefer spicy food and I love Thai cuisine!\",\n",
        "    \"auto-save-test\",\n",
        ")\n",
        "\n",
        "await run_session(\n",
        "    auto_runner,\n",
        "    \"What type of cuisine do I like?\",\n",
        "    \"auto-save-test-2\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "### Session: auto-save-test-3\n",
            "\n",
            "User > I also enjoy Mexican food and prefer medium spice level.\n",
            "Model: > Great! Considering your preference for Mexican cuisine and medium spice levels, how about a **Vegetarian Enchiladas Verdes**?\n",
            "\n",
            "This dish is a fantastic choice because:\n",
            "\n",
            "*   It's a classic Mexican comfort food.\n",
            "*   You can easily control the spice level by adjusting the amount of jalapeños or serrano peppers in the salsa verde.\n",
            "*   It's very versatile with vegetarian fillings.\n",
            "\n",
            "Common ingredients include:\n",
            "\n",
            "*   **Corn tortillas:** For wrapping.\n",
            "*   **Filling:** Black beans, corn, sautéed onions and peppers, and perhaps some crumbled seasoned tofu or a vegetarian cheese blend.\n",
            "*   **Salsa Verde:** Made with tomatillos, cilantro, onion, garlic, and your choice of chiles (like jalapeños for medium heat).\n",
            "*   **Toppings:** Avocado, cilantro, a dollop of sour cream or vegan crema.\n",
            "\n",
            "It's baked until bubbly and delicious.\n",
            "\n",
            "Does Vegetarian Enchiladas Verdes sound like something you'd enjoy?\n",
            "\n",
            "### Session: auto-save-test-4\n",
            "\n",
            "User > Tell me a joke about cooking.\n",
            "Model: > Why did the tomato blush? Because it saw the salad dressing!\n"
          ]
        }
      ],
      "source": [
        "await run_session(\n",
        "    auto_runner,\n",
        "    \"I also enjoy Mexican food and prefer medium spice level.\",\n",
        "    \"auto-save-test-3\",\n",
        ")\n",
        "\n",
        "await run_session(\n",
        "    auto_runner,\n",
        "    \"Tell me a joke about cooking.\",\n",
        "    \"auto-save-test-4\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Search Results:\n",
            "  Found 5 relevant memories\n",
            "\n",
            "  [user]: I am vegetarian and I love Italian cuisine. Can you suggest a pasta recipe?...\n",
            "  [user]: I prefer spicy food and I love Thai cuisine!...\n",
            "  [user]: What type of cuisine do I like?...\n",
            "  [AutoMemoryRecipeAgent]: You like Italian and Thai cuisine. You also mentioned that you prefer spicy food....\n",
            "  [AutoMemoryRecipeAgent]: Great! Considering your preference for Mexican cuisine and medium spice levels, how about a **Vegeta...\n"
          ]
        }
      ],
      "source": [
        "search_response = await memory_service.search_memory(\n",
        "    app_name=APP_NAME, user_id=USER_ID, query=\"cuisine preferences\"\n",
        ")\n",
        "\n",
        "print(\"Final Search Results:\")\n",
        "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
        "print()\n",
        "\n",
        "for memory in search_response.memories:\n",
        "    if memory.content and memory.content.parts:\n",
        "        text = memory.content.parts[0].text[:100]\n",
        "        print(f\"  [{memory.author}]: {text}...\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
